# ğŸ“‚ Project Structure

```
AI-Reel-Optimizer/
â”‚
â”œâ”€â”€ ğŸ“„ readme.md                 # Project overview & features
â”œâ”€â”€ ğŸ“„ Roadmap.md                # Detailed technical roadmap
â”œâ”€â”€ ğŸ“„ QUICKSTART.md             # 5-minute setup guide
â”œâ”€â”€ ğŸ“„ SETUP.md                  # Detailed setup instructions
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md      # This file
â”œâ”€â”€ ğŸ”§ .gitignore                # Git ignore rules
â”œâ”€â”€ ğŸš€ run.sh                    # Auto-start script
â”œâ”€â”€ ğŸ§ª test_backend.py           # Backend test script
â”‚
â”œâ”€â”€ ğŸ backend/                  # FastAPI Backend
â”‚   â”œâ”€â”€ main.py                  # Main FastAPI application
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ .env                     # Environment variables
â”‚   â”œâ”€â”€ .env.example             # Environment template
â”‚   â”‚
â”‚   â””â”€â”€ services/                # Analysis services
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ video_analyzer.py    # OpenCV video analysis
â”‚       â”œâ”€â”€ audio_analyzer.py    # Librosa audio analysis
â”‚       â”œâ”€â”€ content_analyzer.py  # Whisper transcription
â”‚       â””â”€â”€ llm_service.py       # Ollama LLM integration
â”‚
â””â”€â”€ âš›ï¸  frontend/                # Next.js Frontend
    â”œâ”€â”€ package.json             # Node dependencies
    â”œâ”€â”€ tsconfig.json            # TypeScript config
    â”œâ”€â”€ next.config.js           # Next.js config
    â”œâ”€â”€ tailwind.config.js       # Tailwind CSS config
    â”œâ”€â”€ postcss.config.js        # PostCSS config
    â”œâ”€â”€ .env.local               # Frontend environment
    â”œâ”€â”€ .env.local.example       # Environment template
    â”‚
    â”œâ”€â”€ app/                     # Next.js 14 App Router
    â”‚   â”œâ”€â”€ page.tsx             # Main page (home)
    â”‚   â”œâ”€â”€ layout.tsx           # Root layout
    â”‚   â””â”€â”€ globals.css          # Global styles
    â”‚
    â””â”€â”€ components/              # React components
        â”œâ”€â”€ UploadSection.tsx    # Video upload UI
        â””â”€â”€ ResultsDashboard.tsx # Results display UI
```

## ğŸ” Key Files Explained

### Backend

**`main.py`**
- FastAPI application entry point
- `/api/analyze` endpoint for video analysis
- CORS configuration
- File upload handling

**`services/video_analyzer.py`**
- OpenCV-based video analysis
- Brightness, blur, shake detection
- Scene change detection
- First-frame quality analysis

**`services/audio_analyzer.py`**
- Librosa audio processing
- Loudness (LUFS) analysis
- Silence gap detection
- Background noise estimation

**`services/content_analyzer.py`**
- Whisper speech-to-text
- Transcript generation with timestamps
- Language detection

**`services/llm_service.py`**
- Ollama integration
- Platform-specific prompt engineering
- Structured JSON output generation
- Scoring and suggestions

### Frontend

**`app/page.tsx`**
- Main application page
- State management for upload/results
- Component orchestration

**`components/UploadSection.tsx`**
- Video file upload interface
- Platform selection (Instagram/YouTube/Other)
- Form validation
- API communication

**`components/ResultsDashboard.tsx`**
- Results visualization
- Score cards for video/audio/content
- Top priorities display
- Detailed suggestions breakdown

## ğŸ”„ Data Flow

```
User uploads video
    â†“
Frontend (UploadSection)
    â†“
POST /api/analyze
    â†“
Backend (main.py)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parallel Analysis Pipeline     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. VideoAnalyzer                â”‚
â”‚    - Extract frames             â”‚
â”‚    - Analyze quality            â”‚
â”‚                                 â”‚
â”‚ 2. AudioAnalyzer                â”‚
â”‚    - Extract audio              â”‚
â”‚    - Analyze loudness/noise     â”‚
â”‚                                 â”‚
â”‚ 3. ContentAnalyzer              â”‚
â”‚    - Transcribe with Whisper    â”‚
â”‚    - Generate timestamps        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
LLMService (Ollama)
    â†“
Platform-specific analysis
    â†“
Structured JSON response
    â†“
Frontend (ResultsDashboard)
    â†“
User sees suggestions
```

## ğŸ› ï¸ Technology Stack

### Backend
- **FastAPI**: Modern Python web framework
- **OpenCV**: Video frame analysis
- **FFmpeg**: Video/audio extraction
- **Librosa**: Audio signal processing
- **Pydub**: Audio manipulation
- **Whisper**: Speech-to-text (OpenAI)
- **Ollama**: Local LLM inference

### Frontend
- **Next.js 14**: React framework (App Router)
- **TypeScript**: Type safety
- **Tailwind CSS**: Utility-first styling
- **Axios**: HTTP client
- **Lucide React**: Icon library

## ğŸ“Š Analysis Metrics

### Video Metrics
- Duration
- Resolution (width Ã— height)
- FPS (frames per second)
- Average brightness
- Blur score (Laplacian variance)
- Scene changes count
- First-frame quality

### Audio Metrics
- Duration
- Sample rate
- Loudness (dB)
- Silence gaps (timestamps)
- Noise level (spectral flatness)

### Content Metrics
- Full transcript
- Timestamped segments
- Hook strength score (0-10)
- CTA presence (boolean)
- Language detected

## ğŸ¯ Platform-Specific Rules

### Instagram
- Optimal: 15-30s
- Aspect: 9:16 (vertical)
- Hook: First 3s critical
- CTA: Last 5s

### YouTube Shorts
- Optimal: 30-60s
- Aspect: 9:16 (vertical)
- Hook: First 5s
- CTA: Throughout + end

### Other
- Flexible duration
- Flexible aspect ratio
- General best practices

## ğŸš€ Deployment Considerations

### Local Development
- Ollama runs locally (no API costs)
- Whisper downloads once (~140MB)
- Fast iteration cycle

### Production (Future)
- Replace Ollama with cloud LLM (GPT-4, Gemini)
- Add video storage (S3, Supabase)
- Implement user authentication
- Add rate limiting
- Queue system for processing (Celery + Redis)

## ğŸ“ˆ Scalability Path

1. **MVP** (Current): Local processing
2. **Beta**: Cloud LLM + storage
3. **Production**: Distributed processing
4. **Enterprise**: Multi-tenant, analytics

## ğŸ” Security Notes

- Videos are temporarily stored and deleted after analysis
- No user data persistence in MVP
- CORS restricted to localhost
- File size limits enforced
- File type validation

## ğŸ§ª Testing Strategy

1. **Unit Tests**: Individual analyzers
2. **Integration Tests**: Full pipeline
3. **E2E Tests**: Frontend â†’ Backend
4. **Performance Tests**: Processing time benchmarks

## ğŸ“ Environment Variables

### Backend (.env)
```
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3.1:8b
OLLAMA_HOST=http://localhost:11434
PORT=8000
UPLOAD_DIR=./uploads
MAX_VIDEO_SIZE_MB=100
```

### Frontend (.env.local)
```
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ“ Learning Resources

- FastAPI: https://fastapi.tiangolo.com
- OpenCV: https://opencv.org
- Whisper: https://github.com/openai/whisper
- Ollama: https://ollama.ai
- Next.js: https://nextjs.org

---

**Built for AI for Bharat Hackathon ğŸ‡®ğŸ‡³**
